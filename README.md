# RAG-система на русском языке

## Обзор проекта

Данный проект представляет собой полноценную систему Retrieval-Augmented Generation (RAG) с поддержкой русского языка. Система объединяет в себе современные подходы к поиску информации и генерации текста с использованием языковых моделей.

### Ключевые особенности

- **Гибридный поиск**: комбинация векторного поиска и BM25 для максимальной релевантности
- **Переранжирование результатов**: использование CrossEncoder для уточнения релевантности найденных документов
- **Адаптивный выбор контекста**: умная система определения оптимального количества документов для контекста
- **Token-based чанкер**: интеллектуальное разбиение документов на чанки с учетом токенизации LLM, что повышает эффективность использования контекстного окна
- **Отказоустойчивый чанкинг**: интеллектуальное разделение документов на фрагменты с учетом структуры документа
- **Оценка качества**: комплексная система метрик для анализа эффективности RAG с использованием RAGAS
- **Мультиязычная поддержка**: оптимизирована для работы с русским языком через модели intfloat/multilingual-e5-large
- **Современный веб-интерфейс**: удобное взаимодействие с системой через React-интерфейс
- **Кэширование эмбеддингов**: оптимизация производительности через систему кэширования векторных представлений

## Технический стек

### Бэкенд
- **FastAPI**: веб-фреймворк для создания API с более чем 30 эндпоинтами для полноценного управления системой
- **SQLAlchemy**: ORM для работы с базой данных (пользователи, документы, чаты, настройки моделей)
- **Sentence Transformers**: библиотека для работы с векторными представлениями текста (intfloat/multilingual-e5-large)
- **Transformers**: библиотека для работы с трансформерными моделями
- **Spacy**: библиотека для обработки естественного языка с русскоязычной моделью ru_core_news_md
- **Ollama**: интерфейс для запуска локальных языковых моделей (mistral:7b-instruct по умолчанию)
- **Qdrant**: векторная база данных для хранения эмбеддингов и поиска
- **RAGAS**: библиотека для оценки качества RAG-систем с метриками faithfulness, relevance, context recall и precision

### Фронтенд
- **React**: библиотека для построения пользовательских интерфейсов
- **Jest**: фреймворк для тестирования JavaScript-кода

### Хранение данных
- **PostgreSQL**: реляционная база данных для хранения метаданных
- **Qdrant**: векторная база данных для поиска релевантной информации

### Инфраструктура
- **Docker**: контейнеризация приложения
- **Docker Compose**: оркестрация контейнеров
- **Pytest**: фреймворк для тестирования Python-кода

## Архитектура системы

RAG-система состоит из следующих компонентов:

1. **Модуль чанкинга** (`app/chunking/`): разбивает документы на смысловые фрагменты подходящего размера с использованием `SmartChunker`, который автоматически определяет тип документа (markdown, html, plain text) и применяет соответствующую стратегию разбиения.
2. **Модуль индексации** (`app/retrieval/`): преобразует текстовые фрагменты в векторные представления с помощью `VectorizerWithCache` и сохраняет их в `QdrantIndex` для быстрого поиска.
3. **Модуль поиска**: находит релевантные фрагменты для заданного вопроса, используя гибридный подход (векторный поиск + BM25) и переранжирование через CrossEncoder.
4. **Модуль генерации**: формирует промпт на основе найденных фрагментов и отправляет его в языковую модель через Ollama API.
5. **Модуль оценки** (`app/evaluation/`): анализирует качество работы системы с использованием метрик RAGAS и предоставляет детальные отчеты.
6. **API** (`app/main.py`): предоставляет более 30 эндпоинтов для взаимодействия с системой, включая управление документами, запросы, оценку и настройку параметров.
7. **Веб-интерфейс** (`frontend/`): обеспечивает удобное пользовательское взаимодействие через React-приложение.

## Запуск проекта

### Предварительные требования

- Python 3.10+
- Docker и Docker Compose
- Git
- Node.js и npm (для разработки фронтенда)
- (Опционально) NVIDIA GPU с установленным CUDA для ускорения работы моделей
- Ollama (для локального запуска)

### Запуск через Docker

Самый простой способ запустить всю систему - использовать Docker Compose:

1. Клонируйте репозиторий:
   ```bash
   git clone <url-репозитория>
   cd rag
   ```

2. Создайте файл .env на основе .env.example:
   ```bash
   cp .env.example .env
   ```

3. (Опционально) Отредактируйте .env под свои нужды:
   ```
   # Настройки языковой модели
   OLLAMA_MODEL=mistral:7b-instruct
   OLLAMA_HOST=http://localhost:11434
   # ...другие настройки
   ```

4. Запустите сервисы через Docker Compose:
   ```bash
   docker-compose up -d
   ```
   
   Это запустит:
   - PostgreSQL (база данных)
   - Qdrant (векторная база данных)
   - FastAPI бэкенд
   - React фронтенд
   
   При первом запуске будут автоматически созданы необходимые таблицы в базе данных.

5. Проверьте, что все сервисы запущены:
   ```bash
   python check_services.py
   ```

6. Откройте веб-интерфейс по адресу [http://localhost:3000](http://localhost:3000)

#### Просмотр логов Docker-контейнеров

```bash
# Логи всех контейнеров
docker-compose logs

# Логи конкретного сервиса
docker-compose logs rag-api
```

#### Остановка и удаление контейнеров

```bash
# Остановка сервисов
docker-compose stop

# Остановка и удаление контейнеров
docker-compose down

# Остановка, удаление контейнеров и томов с данными
docker-compose down -v
```

### Локальный запуск для разработки

Для разработки и отладки удобнее запускать компоненты системы локально:

1. Установите Ollama:
   ```bash
   # macOS / Linux
   curl -fsSL https://ollama.com/install.sh | sh
   
   # Windows
   # Скачайте установщик с https://ollama.com
   ```

2. Загрузите модель Mistral 7B:
   ```bash
   ollama pull mistral:7b-instruct
   ```

3. Установите PostgreSQL и запустите его:
   ```bash
   # Можно использовать Docker
   docker run -d --name postgres \
     -e POSTGRES_USER=postgres \
     -e POSTGRES_PASSWORD=mysecretpassword \
     -e POSTGRES_DB=postgres \
     -p 5432:5432 \
     postgres:15
   ```

4. Установите Qdrant и запустите его:
   ```bash
   # Через Docker
   docker run -d --name qdrant \
     -p 6333:6333 \
     -p 6334:6334 \
     -v $(pwd)/qdrant_data:/qdrant/storage \
     qdrant/qdrant
   ```

5. Создайте и активируйте виртуальное окружение Python:
   ```bash
   python -m venv venv
   
   # Windows
   venv\Scripts\activate
   
   # macOS / Linux
   source venv/bin/activate
   ```

6. Установите зависимости Python:
   ```bash
   pip install -r requirements.txt
   ```

7. Создайте файл .env:
   ```bash
   cp .env.example .env
   ```
   
   При необходимости отредактируйте параметры подключения к базе данных и другие настройки.

8. Создайте пользователя и базу данных (если запускаете PostgreSQL локально):
   ```bash
   python create_pg_user_and_db.py
   ```

9. Запустите бэкенд:
   ```bash
   # Вариант 1: Через скрипт
   python -m scripts.run_app
   
   # Вариант 2: Напрямую через uvicorn
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

10. В отдельном терминале запустите фронтенд:
    ```bash
    cd frontend
    npm install
    npm start
    ```

11. Откройте веб-интерфейс по адресу [http://localhost:3000](http://localhost:3000)

#### Перестроение индекса

Если вам нужно перестроить векторный индекс:

```bash
python -m scripts.rebuild_index
```

#### Проверка состояния сервисов

```bash
python check_services.py
```

## Использование системы

### API-эндпоинты

- `POST /api/ask` - Задать вопрос RAG-системе
- `POST /api/documents/upload` - Загрузить новые документы в систему
- `GET /api/documents` - Получить список загруженных документов
- `DELETE /api/documents/{document_id}` - Удалить документ
- `GET /api/evaluate-ragas/results` - Получить результаты оценки системы
- `POST /api/evaluate-ragas/async` - Запустить оценку качества RAG асинхронно
- `GET /api/healthcheck` - Проверить состояние системы и компонентов
- `POST /api/model/settings` - Обновить настройки модели

#### Интерактивная документация API

FastAPI автоматически генерирует интерактивную документацию для всех эндпоинтов:

- Swagger UI: доступна по адресу `/docs` (например, http://localhost:8000/docs)
- ReDoc: доступна по адресу `/redoc` (например, http://localhost:8000/redoc)

С помощью этой документации вы можете:
- Просматривать все доступные эндпоинты и их параметры
- Тестировать API запросы прямо из браузера
- Изучать схемы запросов и ответов

### Оценка качества RAG

Система поддерживает комплексную оценку качества RAG с использованием библиотеки RAGAS:

```bash
# Запуск оценки с использованием встроенного датасета (sberquad или RuBQ)
python test_rag_eval.py --builtin --dataset sberquad
```

Доступные метрики:
- Faithfulness (достоверность) - насколько ответ соответствует предоставленному контексту
- Answer Relevancy (релевантность ответа) - насколько ответ соответствует вопросу
- Context Recall (полнота контекста) - насколько полно контекст покрывает информацию, необходимую для ответа
- Context Precision (точность контекста) - насколько точно контекст соответствует информационной потребности в вопросе

## Настройка и конфигурация

Система настраивается через файл .env. Основные параметры:

```
# Языковая модель
OLLAMA_MODEL=mistral:7b-instruct
OLLAMA_TIMEOUT=120

# Модели для embeddings и ранжирования
EMBEDDING_MODEL=intfloat/multilingual-e5-large
CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-12-v2

# Настройки чанкинга
CHUNK_SIZE=400
CHUNK_OVERLAP=100
LANGUAGE=russian
SPACY_MODEL=ru_core_news_md

# Настройки поиска
USE_HYBRID_SEARCH=True
USE_RERANKER=True
DENSE_WEIGHT=0.6
RERANKER_WEIGHT=0.6
USE_ADAPTIVE_K=True
MIN_K=2
MAX_K=5
MIN_SCORE_THRESHOLD=0.45

## Настройка параметров

Настройки системы можно изменить с помощью переменных окружения или путем редактирования файла `.env` в корне проекта.

#### Основные параметры

| Переменная | Описание | Значение по умолчанию |
|------------|----------|----------------------|
| `EMBEDDING_MODEL` | Модель для эмбеддингов | `intfloat/multilingual-e5-large` |
| `LLM_MODEL` | Модель для генерации | `mistral:7b-instruct` |
| `USE_HYBRID_SEARCH` | Использовать гибридный поиск | `true` |
| `USE_RERANKER` | Использовать переранжирование | `true` |

#### Настройки чанкера

| Переменная | Описание | Значение по умолчанию |
|------------|----------|----------------------|
| `USE_TOKEN_CHUNKER` | Использовать токеновый чанкер вместо символьного | `true` |
| `MAX_TOKENS` | Максимальное количество токенов в чанке (для токенового чанкера) | `512` |
| `OVERLAP_TOKENS` | Перекрытие между чанками в токенах (для токенового чанкера) | `20` |
| `TOKEN_MODEL` | Модель для токенизатора | `mistralai/Mistral-7B-Instruct-v0.2` |
| `CHUNK_SIZE` | Размер чанка в символах (для символьного чанкера) | `400` |
| `CHUNK_OVERLAP` | Перекрытие между чанками в символах (для символьного чанкера) | `200` |

#### Настройки поиска

| Переменная | Описание | Значение по умолчанию |
|------------|----------|----------------------|
| `USE_ADAPTIVE_K` | Использовать адаптивный выбор контекста | `true` |
| `MIN_K` | Минимальное количество релевантных документов | `2` |
| `MAX_K` | Максимальное количество релевантных документов | `5` |
| `MIN_SCORE_THRESHOLD` | Пороговое значение для выбора релевантных документов | `0.45` |

## Структура проекта

```
rag/
├── app/                      # Основной код приложения
│   ├── chunking/             # Модули для разбиения документов на фрагменты
│   ├── retrieval/            # Компоненты для поиска релевантных документов
│   ├── evaluation/           # Инструменты для оценки качества RAG
│   │   ├── __init__.py       # Инициализация модуля оценки
│   │   ├── logger.py         # Логирование процесса оценки
│   │   ├── results/          # Результаты оценок
│   │   ├── datasets/         # Встроенные датасеты (sberquad, RuBQ)
│   │   └── error_logs/       # Логи ошибок при оценке
│   ├── monitoring/           # Мониторинг системы и логирование событий 
│   ├── utils/                # Вспомогательные утилиты
│   ├── config.py             # Конфигурация приложения
│   ├── logging_config.py     # Настройки логирования
│   ├── database.py           # Интеграция с базой данных
│   ├── main.py               # Основной файл FastAPI с эндпоинтами
│   ├── models.py             # Модели данных SQLAlchemy
│   ├── ollama_client.py      # Клиент для взаимодействия с Ollama
│   ├── rag.py                # Основная логика RAG (индексация, поиск, генерация)
│   └── schemas.py            # Схемы Pydantic для валидации данных
├── frontend/                 # React-приложение для веб-интерфейса
│   ├── src/                  # Исходный код React-приложения
│   │   ├── components/       # React-компоненты
│   │   ├── pages/            # Страницы приложения
│   │   ├── services/         # Сервисы для API-запросов
│   │   ├── contexts/         # React-контексты
│   │   ├── tests/            # Тесты компонентов
│   │   ├── App.js            # Основной компонент приложения
│   │   └── index.js          # Точка входа
│   └── public/               # Статические файлы
├── scripts/                  # Вспомогательные скрипты
│   ├── rebuild_index.py      # Перестроение индекса
│   ├── run_app.py            # Запуск приложения
│   └── run_evaluation.py     # Запуск оценки качества
├── tests/                    # Тесты
├── logs/                     # Директория для логов
├── qdrant_data/              # Данные Qdrant
├── indexes/                  # Директория для хранения индексов
├── cache/                    # Кэшированные эмбеддинги
├── .env.example              # Пример конфигурации
├── docker-compose.yml        # Конфигурация Docker Compose
├── Dockerfile                # Dockerfile для сборки приложения
├── test_rag_eval.py          # Тестирование скрипта оценки RAG
└── requirements.txt          # Зависимости Python
```

## Тестирование

Запуск всех тестов:
```bash
pytest
```

Запуск конкретных тестов:
```bash
pytest tests/test_rag_quality.py
```

## Устранение неполадок

### Проблемы с подключением к Ollama

Если система не может подключиться к Ollama, убедитесь, что:
1. Ollama запущен (`ollama serve`)
2. Нужная модель загружена (`ollama list`)
3. Правильно указан хост в .env (`OLLAMA_HOST=http://localhost:11434`)

### Проблемы с базой данных

Если есть проблемы с подключением к PostgreSQL:
1. Проверьте, что сервис запущен
2. Проверьте настройки подключения в .env
3. Выполните миграцию базы данных вручную:
   ```bash
   # Подключение к PostgreSQL
   psql -U postgres -h localhost
   ```

## Компоненты системы

### Модуль чанкинга

Система предлагает два типа чанкеров:

#### 1. Character-based чанкер (RobustChunker)

Разбивает документы на фрагменты фиксированного размера с заданным перекрытием, используя символы в качестве единицы измерения.

- Поддерживает различные типы контента (текст, markdown, HTML, код, JSON, CSV, XML, YAML)
- Интеллектуально обрабатывает структуру документа, сохраняя семантически связанные части вместе
- Использует механизмы резервирования для обработки сложных случаев

#### 2. Token-based чанкер (TokenChunker) - НОВЫЙ

Разбивает документы с учетом токенизации языковой модели, оптимизируя размер чанков под контекстное окно LLM.

- Использует тот же токенизатор, что и целевая языковая модель
- Создает чанки, занимающие оптимальный процент контекстного окна (по умолчанию ~25%)
- Уменьшает количество чанков и улучшает эффективность использования контекста
- Обеспечивает более высокое качество ответов благодаря более информативным чанкам

#### Сравнение чанкеров

| Метрика | Character-based | Token-based |
|---------|----------------|-------------|
| Ед. измерения | Символы | Токены LLM |
| Эффективность окна | ~5% | ~20-25% |
| Кол-во чанков | Больше | Меньше (~на 80-90%) |
| Интеграция с LLM | Ограниченная | Высокая |

По умолчанию система использует Token-based чанкер, но вы можете переключиться на Character-based при необходимости.

### Индексация и поиск