Учёные из Калифорнийского университета провели эксперимент, в котором проверили три языковые модели с помощью пятиминутного теста Тьюринга. Пройти тест смог только чат-бот ChatGPT-4.
Тест был создан математиком Аланом Тьюрингом в начале 50-х годов прошлого века, чтобы определить, является ли ИИ приближенным к человеку по уровню мышления. Суть теста в том, что человек переписывается с невидимым собеседником в течение какого-то времени, после чего он должен решить, с кем он общался: с другим человеком или искусственным интеллектом. Если большая часть участников эксперимента примут ИИ за живого человека, то тест пройден. Этот способ проверки часто критикуют, и даже сам Тьюринг называл его несовершенным, но всё равно он считается важным при проверке способностей нейросетей.
В новом исследовании участвовали 402 человека, которые в течение пяти минут переписывались со случайным собеседником. Им мог оказаться как реальный человек, так и одна из трёх языковых моделей:
• ELIZA;
• ChatGPT-3.5;
• ChatGPT-4.
Модель ChatGPT-4 смогла обмануть людей в 54% случаев, а ChatGPT-3.5 в 50%. Модель ELIZA за человека приняли только 22% участников.
Как считают авторы, результаты исследования показывают не только значительный прогресс языковых моделей, но и напоминают об ограничениях теста Тьюринга. Участники эксперимента часто оценивали не точность ответа собеседника, а его стиль общения, и на основании этого делали вывод о человечности. Но полученные данные позволяют сделать вывод, что в будущем всё больше задач по общению с клиентами будут отдавать нейросетям, однако вместе с этим будет больше случаев дезинформации и мошенничества с использованием ИИ.